{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93179240-9c5f-4ba6-a1c7-3a981624f794",
   "metadata": {},
   "source": [
    "# Data Ingestion to Knowledge Base for Amazon Bedrock\n",
    "**_Use of Knowledge Bases for Amazon Bedrock with Amazon OpenSearch Serverless as a vector database for storing embeddings_**\n",
    "\n",
    "This notebook provides sample code for a data pipeline that ingests documents (typically stored in Amazon S3) into a knowledge base i.e. a vector database such as Amazon OpenSearch Service Serverless.\n",
    "\n",
    "This notebook works well with the `Data Science 3.0` kernel on a SageMaker Studio `ml.t3.medium` instance.\n",
    "\n",
    "Here is a list of packages that are used in this notebook.\n",
    "```\n",
    "!pip list | grep -E -w \"sagemaker|langchain|langchainhub|opensearch-py|sh\"\n",
    "----------------------------------------------------------------------------------------\n",
    "boto3                                1.34.107\n",
    "langchain                            0.1.16\n",
    "langchain-aws                        0.1.0\n",
    "langchain-community                  0.0.34\n",
    "langchain-core                       0.1.52\n",
    "langchain-text-splitters             0.0.2\n",
    "langchainhub                         0.1.15\n",
    "opensearch-py                        2.3.1\n",
    "sagemaker                            2.215.0\n",
    "SQLAlchemy                           2.0.28\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b007828-1c25-4b71-9573-d7cec0417844",
   "metadata": {},
   "source": [
    "# Prerequsites\n",
    "\n",
    "The following IAM policies need to be attached to the SageMaker execution role that you use to run this notebook:\n",
    "\n",
    "- AmazonSageMakerFullAccess\n",
    "- AWSCloudFormationReadOnlyAccess\n",
    "- AmazonS3FullAccess\n",
    "- inline policy for Amazon OpenSearch Service Serverless\n",
    "  ```\n",
    "  {\n",
    "      \"Version\": \"2012-10-17\",\n",
    "      \"Statement\": [\n",
    "          {\n",
    "              \"Action\": [\n",
    "                  \"aoss:BatchGetCollection\",\n",
    "                  \"aoss:GetAccessPolicy\",\n",
    "                  \"aoss:GetAccountSettings\",\n",
    "                  \"aoss:GetSecurityConfig\",\n",
    "                  \"aoss:GetSecurityPolicy\",\n",
    "                  \"aoss:ListAccessPolicies\",\n",
    "                  \"aoss:ListCollections\",\n",
    "                  \"aoss:ListSecurityConfigs\",\n",
    "                  \"aoss:ListSecurityPolicies\",\n",
    "                  \"aoss:ListTagsForResource\",\n",
    "                  \"aoss:ListVpcEndpoints\",\n",
    "                  \"aoss:UpdateAccessPolicy\"\n",
    "              ],\n",
    "              \"Resource\": \"*\",\n",
    "              \"Effect\": \"Allow\",\n",
    "              \"Sid\": \"UsingOpenSearchServerlessIntheConsole\"\n",
    "          },\n",
    "          {\n",
    "              \"Action\": \"aoss:APIAccessAll\",\n",
    "              \"Resource\": \"arn:aws:aoss:us-east-1:819320734790:collection/*\",\n",
    "              \"Effect\": \"Allow\",\n",
    "              \"Sid\": \"OpenSearchServerlessCollectionAccess\"\n",
    "          },\n",
    "          {\n",
    "              \"Action\": \"aoss:DashboardsAccessAll\",\n",
    "              \"Resource\": \"arn:aws:aoss:us-east-1:819320734790:dashboards/default\",\n",
    "              \"Effect\": \"Allow\",\n",
    "              \"Sid\": \"OpenSearchServerlessDashboardAccess\"\n",
    "          }\n",
    "      ]\n",
    "  }\n",
    "  ```\n",
    "- inline policy for Amazon Bedrock\n",
    "  ```\n",
    "  {\n",
    "      \"Version\": \"2012-10-17\",\n",
    "      \"Statement\": [\n",
    "          {\n",
    "              \"Action\": [\n",
    "                  \"bedrock:ListDataSources\",\n",
    "                  \"bedrock:ListFoundationModelAgreementOffers\",\n",
    "                  \"bedrock:ListFoundationModels\",\n",
    "                  \"bedrock:ListIngestionJobs\",\n",
    "                  \"bedrock:ListKnowledgeBases\",\n",
    "                  \"bedrock:ListModelInvocationJobs\"\n",
    "              ],\n",
    "              \"Resource\": \"*\",\n",
    "              \"Effect\": \"Allow\",\n",
    "              \"Sid\": \"BedrockList\"\n",
    "          },\n",
    "          {\n",
    "              \"Action\": [\n",
    "                  \"bedrock:GetDataSource\",\n",
    "                  \"bedrock:GetFoundationModel\",\n",
    "                  \"bedrock:GetFoundationModelAvailability\",\n",
    "                  \"bedrock:GetIngestionJob\",\n",
    "                  \"bedrock:GetKnowledgeBase\",\n",
    "                  \"bedrock:GetModelInvocationJob\",\n",
    "                  \"bedrock:InvokeModel\",\n",
    "                  \"bedrock:InvokeModelWithResponseStream\",\n",
    "                  \"bedrock:ListTagsForResource\",\n",
    "                  \"bedrock:Retrieve\"\n",
    "              ],\n",
    "              \"Resource\": \"*\",\n",
    "              \"Effect\": \"Allow\",\n",
    "              \"Sid\": \"BedrockRead\"\n",
    "          },\n",
    "          {\n",
    "              \"Action\": [\n",
    "                  \"bedrock:CreateFoundationModelAgreement\",\n",
    "                  \"bedrock:CreateModelInvocationJob\",\n",
    "                  \"bedrock:CreateProvisionedModelThroughput\",\n",
    "                  \"bedrock:DeleteFoundationModelAgreement\",\n",
    "                  \"bedrock:DeleteModelInvocationLoggingConfiguration\",\n",
    "                  \"bedrock:DeleteProvisionedModelThroughput\",\n",
    "                  \"bedrock:PutModelInvocationLoggingConfiguration\",\n",
    "                  \"bedrock:RetrieveAndGenerate\",\n",
    "                  \"bedrock:StartIngestionJob\",\n",
    "                  \"bedrock:UpdateDataSource\",\n",
    "                  \"bedrock:UpdateKnowledgeBase\"\n",
    "              ],\n",
    "              \"Resource\": \"*\",\n",
    "              \"Effect\": \"Allow\",\n",
    "              \"Sid\": \"BedrockWrite\"\n",
    "          },\n",
    "          {\n",
    "              \"Action\": [\n",
    "                  \"bedrock:TagResource\",\n",
    "                  \"bedrock:UntagResource\"\n",
    "              ],\n",
    "              \"Resource\": \"*\",\n",
    "              \"Effect\": \"Allow\",\n",
    "              \"Sid\": \"BedrockTagging\"\n",
    "          }\n",
    "      ]\n",
    "  }\n",
    "  ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2f1199-092d-40eb-8a9b-fef0ad619ae3",
   "metadata": {},
   "source": [
    "# Data Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79aae52c-cd7a-4637-a07d-9c0131dc7d0a",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "Install the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e64f84-b7ac-427d-b5a8-cf98b430be9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -Uq pip\n",
    "\n",
    "!pip install -Uq langchain==0.1.16\n",
    "!pip install -Uq \"boto3>=1.26.159\" langchain-aws==0.1.0\n",
    "!pip install -Uq langchain-community==0.0.34\n",
    "!pip install -Uq langchainhub==0.1.15\n",
    "!pip install -Uq SQLAlchemy==2.0.28\n",
    "\n",
    "!pip install -Uq opensearch-py==2.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a8ab9f-fc0e-4866-a981-01288bf33883",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boto3                                1.34.107\n",
      "langchain                            0.1.16\n",
      "langchain-aws                        0.1.0\n",
      "langchain-community                  0.0.34\n",
      "langchain-core                       0.1.52\n",
      "langchain-text-splitters             0.0.2\n",
      "langchainhub                         0.1.15\n",
      "opensearch-py                        2.3.1\n",
      "sagemaker                            2.215.0\n",
      "sagemaker-data-insights              0.3.3\n",
      "sagemaker-datawrangler               0.4.3\n",
      "sagemaker-headless-execution-driver  0.0.13\n",
      "sagemaker-scikit-learn-extension     2.5.0\n",
      "sagemaker-studio-analytics-extension 0.0.20\n",
      "sagemaker-studio-sparkmagic-lib      0.1.4\n",
      "SQLAlchemy                           2.0.28\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep -E -w \"boto3|sagemaker|langchain|langchainhub|opensearch-py|SQLAlchemy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194877e9-ee48-4a1e-96ee-aa4fdbfa5ca8",
   "metadata": {},
   "source": [
    "## Step 2: Check if Amazon OpenSearch Serverless Collection exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92723a2-b7f9-4276-bc9f-0ced3da9bced",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "import time\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6ad587-0a05-4db5-804c-384673b4d62c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "aws_region = boto3.Session().region_name\n",
    "sagemaker_execution_role = get_execution_role()\n",
    "\n",
    "aws_region, sagemaker_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a80019-a475-4313-a820-3e4fa92d1e8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import (\n",
    "    check_if_index_exists,\n",
    "    get_aws_auth,\n",
    "    get_aoss_data_access_policy,\n",
    "    update_aoss_data_access_policy_with_caller_arn,\n",
    "    get_cfn_outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74efbfa-0e7f-4f55-ba5d-6046fd71bbc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CFN_STACK_NAME = \"BedrockKnowledgeBaseStack\"\n",
    "cfn_stack_outputs = get_cfn_outputs(CFN_STACK_NAME, aws_region)\n",
    "\n",
    "knowledge_base_id = cfn_stack_outputs['KnowledgeBaseId']\n",
    "data_source_name = cfn_stack_outputs['DataSourceName']\n",
    "\n",
    "knowledge_base_id, data_source_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebad79c-507c-43c4-a4ed-1b2c80768317",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bedrock_agent_client = boto3.client(\n",
    "    'bedrock-agent',\n",
    "    region_name=aws_region\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b011d5-ea91-4eb7-835a-cb005056fc0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get KnowledgeBase\n",
    "\n",
    "response = bedrock_agent_client.get_knowledge_base(\n",
    "    knowledgeBaseId=knowledge_base_id\n",
    ")\n",
    "\n",
    "kb_info = response['knowledgeBase']\n",
    "kb_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bd563f-c463-4762-bac4-0b908ed69cb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "collection_arn = kb_info['storageConfiguration']['opensearchServerlessConfiguration']['collectionArn']\n",
    "collection_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201567ce-f73f-4f5a-8dac-67ae7e4305ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "region_name = aws_region\n",
    "collection_id = collection_arn.split('/')[-1]\n",
    "\n",
    "opensearch_endpoint_url = f\"https://{collection_id}.{region_name}.aoss.amazonaws.com\"\n",
    "opensearch_endpoint_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559132b2-b9ae-4c5e-8715-88b6c36b2bc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "opensearch_vector_index = kb_info['storageConfiguration']['opensearchServerlessConfiguration']['vectorIndexName']\n",
    "opensearch_vector_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee42dea7-bd59-4163-a61c-f453678f3205",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_access_policy = get_aoss_data_access_policy(collection_id, aws_region)\n",
    "opensearch_data_access_policy_name = data_access_policy['name']\n",
    "opensearch_data_access_policy_name, data_access_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c5b641-cabe-4120-913e-0bf7c73f48ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "is_ok = update_aoss_data_access_policy_with_caller_arn(\n",
    "    policy_name=opensearch_data_access_policy_name,\n",
    "    caller_arn=sagemaker_execution_role,\n",
    "    region_name=aws_region\n",
    ")\n",
    "\n",
    "is_ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a824ea36-baca-42fc-b088-1f76abb8cb09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aws_auth = get_aws_auth(region_name=aws_region)\n",
    "\n",
    "exists = check_if_index_exists(\n",
    "    index_name=opensearch_vector_index,\n",
    "    host=opensearch_endpoint_url,\n",
    "    auth=aws_auth\n",
    ")\n",
    "\n",
    "exists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c017bc3f-e507-4f0c-b640-ea774c5ea9c8",
   "metadata": {},
   "source": [
    "## Step 3: Download and prepare dataset\n",
    "\n",
    "### Dataset\n",
    "\n",
    "In this example, you will use several years of Amazon's Letter to Shareholders as a text corpus to perform Q&A on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5752d3a8-2df2-474f-9acb-3a24b3b1be46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "data_root_dir = Path('./data')\n",
    "data_root_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "urls = [\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2020/ar/2019-Shareholder-Letter.pdf',\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2021/ar/Amazon-2020-Shareholder-Letter-and-1997-Shareholder-Letter.pdf',\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2022/ar/2021-Shareholder-Letter.pdf',\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2023/ar/2022-Shareholder-Letter.pdf',\n",
    "]\n",
    "\n",
    "filenames = [\n",
    "    'AMZN-2019-Shareholder-Letter.pdf',\n",
    "    'AMZN-2020-Shareholder-Letter.pdf',\n",
    "    'AMZN-2021-Shareholder-Letter.pdf',\n",
    "    'AMZN-2022-Shareholder-Letter.pdf',\n",
    "]\n",
    "\n",
    "for idx, url in enumerate(urls):\n",
    "    file_path = data_root_dir.joinpath(filenames[idx])\n",
    "    urlretrieve(url, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2604717-e563-473f-9b78-ccbee2ffb84c",
   "metadata": {},
   "source": [
    "## Step 4: Upload data to S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ffed6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get DataSourceId\n",
    "\n",
    "response = bedrock_agent_client.list_data_sources(\n",
    "    knowledgeBaseId=knowledge_base_id\n",
    ")\n",
    "\n",
    "data_source_id = response['dataSourceSummaries'][0]['dataSourceId']\n",
    "data_source_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8202474f-6fe1-4ffd-9aa9-884a7a9dfd4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get DataSource\n",
    "\n",
    "response = bedrock_agent_client.get_data_source(\n",
    "    knowledgeBaseId=knowledge_base_id,\n",
    "    dataSourceId=data_source_id\n",
    ")\n",
    "\n",
    "ds_info = response['dataSource']\n",
    "ds_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc23a94-9841-4866-96ee-3fc10dd11f17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_source_s3_bucket_arn = ds_info['dataSourceConfiguration']['s3Configuration']['bucketArn']\n",
    "data_source_s3_bucket_name = data_source_s3_bucket_arn.split(':')[-1]\n",
    "data_source_s3_bucket_arn, data_source_s3_bucket_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3951301-1c0a-4855-ad56-cfa190448ccf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Uploader\n",
    "\n",
    "bucket, prefix = data_source_s3_bucket_name, 'data' # Replace prefix with yours\n",
    "\n",
    "dataset_s3_path = S3Uploader.upload(\n",
    "    local_path=str(data_root_dir), desired_s3_uri=f\"s3://{bucket}/{prefix}\"\n",
    ")\n",
    "\n",
    "dataset_s3_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a564de-8a13-4a06-b36c-168e93ab638f",
   "metadata": {},
   "source": [
    "## Step 5: Start ingestion job\n",
    "\n",
    "Once the Knowledge Base and Data Source are created by deploying CDK Stacks, we can start the ingestion job. During the ingestion job, Knowledge Base will fetch the documents in the data source, pre-process it to extract text, chunk it based on the chunking size provided, create embeddings of each chunk and then write it to the vector database, in this case Amazon OpenSearch Serverless Service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfb15a3-7429-4a92-8e19-54bbe3e8074d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Start an ingestion job\n",
    "\n",
    "start_job_response = bedrock_agent_client.start_ingestion_job(\n",
    "    knowledgeBaseId=knowledge_base_id,\n",
    "    dataSourceId=data_source_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9355de-bc13-4615-be60-bfd5e2062429",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "job = start_job_response[\"ingestionJob\"]\n",
    "pp.pprint(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8342290b-8762-46d2-a9a4-e59dca535576",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "while (job['status'] != 'COMPLETE'):\n",
    "    get_job_response = bedrock_agent_client.get_ingestion_job(\n",
    "        knowledgeBaseId=knowledge_base_id,\n",
    "        dataSourceId=data_source_id,\n",
    "        ingestionJobId=job[\"ingestionJobId\"]\n",
    "    )\n",
    "\n",
    "    job = get_job_response[\"ingestionJob\"]\n",
    "    pp.pprint(job)\n",
    "    time.sleep(30)\n",
    "\n",
    "pp.pprint(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4f9006-f49d-4592-9ef4-1ad8a6d54e14",
   "metadata": {},
   "source": [
    "# Test the knowledge base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c14305c-8de7-4fbe-ac02-ecfac4b5d8d7",
   "metadata": {},
   "source": [
    "## Using Knowlege Bases for Amazon Bedrock APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41719136-d8ff-4cfb-ba09-12d88e702b57",
   "metadata": {},
   "source": [
    "### RetrieveAndGenerate API\n",
    "\n",
    "Behind the scenes, RetrieveAndGenerate API converts queries into embeddings, searches the knowledge base, and then augments the foundation model prompt with the search results as context information and returns the FM-generated response to the question. For multi-turn conversations, Knowledge Bases manage short-term memory of the conversation to provide more contextual results.\n",
    "\n",
    "The output of the RetrieveAndGenerate API includes the generated response, source attribution as well as the retrieved text chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba998876-7cb7-4579-a506-d528bcc12648",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bedrock_agent_runtime_client = boto3.client(\n",
    "    \"bedrock-agent-runtime\",\n",
    "    region_name=aws_region\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301dbfeb-a549-4cd2-8dae-5cbd75a82e9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "model_arn = f\"arn:aws:bedrock:{aws_region}::foundation-model/{model_id}\"\n",
    "\n",
    "model_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6155a0-509d-403e-80ee-4a213641612b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"What is Amazon's doing in the field of generative AI?\"\n",
    "\n",
    "response = bedrock_agent_runtime_client.retrieve_and_generate(\n",
    "    input={\n",
    "        'text': query\n",
    "    },\n",
    "    retrieveAndGenerateConfiguration={\n",
    "        'type': 'KNOWLEDGE_BASE',\n",
    "        'knowledgeBaseConfiguration': {\n",
    "            'knowledgeBaseId': knowledge_base_id,\n",
    "            'modelArn': model_arn\n",
    "        }\n",
    "    },\n",
    ")\n",
    "\n",
    "generated_text = response['output']['text']\n",
    "pp.pprint(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ddebe0-f5c6-4d17-a256-81c1b0c5ba3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## print out the source attribution/citations from the original documents to see if the response generated belongs to the context.\n",
    "\n",
    "citations = response[\"citations\"]\n",
    "contexts = []\n",
    "for citation in citations:\n",
    "    retrievedReferences = citation[\"retrievedReferences\"]\n",
    "    for reference in retrievedReferences:\n",
    "        contexts.append(reference[\"content\"][\"text\"])\n",
    "\n",
    "pp.pprint(contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eec24bf-b591-4148-83b9-bae28a2d83bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Retrieve API\n",
    "\n",
    "Retrieve API converts user queries into embeddings, searches the knowledge base, and returns the relevant results, giving you more control to build custom workï¬‚ows on top of the semantic search results. The output of the Retrieve API includes the the retrieved text chunks, the location type and URI of the source data, as well as the relevance scores of the retrievals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0ba3fd-8043-4e15-89c4-c4c014e01291",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# retreive api for fetching only the relevant context.\n",
    "\n",
    "relevant_documents = bedrock_agent_runtime_client.retrieve(\n",
    "    retrievalQuery= {\n",
    "        'text': query\n",
    "    },\n",
    "    knowledgeBaseId=knowledge_base_id,\n",
    "    retrievalConfiguration= {\n",
    "        'vectorSearchConfiguration': {\n",
    "            'numberOfResults': 3 # will fetch top 3 documents which matches closely with the query.\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "pp.pprint(relevant_documents[\"retrievalResults\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffde5a6b-75e9-461b-9f16-f7b9ae3f88c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Using LangChain Integration with AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c71329-3b8d-4959-bd69-c6b611496eef",
   "metadata": {},
   "source": [
    "### Using the Knowledge Bases Retriever (AmazonKnowledgeBasesRetriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c70986e-ef59-4ab9-8a66-886118fc71ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_aws import AmazonKnowledgeBasesRetriever\n",
    "\n",
    "\n",
    "retriever = AmazonKnowledgeBasesRetriever(\n",
    "    knowledge_base_id=knowledge_base_id,\n",
    "    retrieval_config={\n",
    "        \"vectorSearchConfiguration\": {\n",
    "            \"numberOfResults\": 3,\n",
    "            # 'overrideSearchType': \"SEMANTIC\", # optional, [SEMANTIC, HYBRID]\n",
    "        }\n",
    "    },\n",
    "    region_name=aws_region\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66765b81-ac1c-4220-890e-4adea31d29d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"What is Amazon doing in the field of Generative AI?\"\n",
    "\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "pp.pprint(retrieved_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2f38cb-3d7b-4200-8135-61e63d9268a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Q&A with RAG using LangChain RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8642e57d-a94f-4d4c-90a7-6cff44cb29f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrock as BedrockChat\n",
    "\n",
    "\n",
    "llm = BedrockChat(\n",
    "    model_id=model_id,\n",
    "    model_kwargs={\n",
    "        \"max_tokens\": 512,\n",
    "        \"temperature\": 0,\n",
    "        \"top_p\": 0.9\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4589ec5e-0513-4e7f-95aa-039d1bc05c83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Human: You are a financial advisor AI system, and provides answers to questions by using fact based and statistical information when possible.\n",
    "Use the following pieces of information to provide a concise answer to the question enclosed in <question> tags.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "\n",
    "The response should be specific and use statistics or numbers when possible.\n",
    "\n",
    "Assistant:\"\"\"\n",
    "claude_prompt = PromptTemplate(template=PROMPT_TEMPLATE,\n",
    "                               input_variables=[\"context\", \"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb862778-e256-4957-90f0-074a8c3c37bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": claude_prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba43394-82ea-44cd-a7b2-18df0b3c0e0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "answer = qa.invoke(query)\n",
    "pp.pprint(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4b9d48-8226-42f7-a59b-2e2c65651a3c",
   "metadata": {},
   "source": [
    "### Q&A with RAG using LCEL (LangChain Expression Language) Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea7fb7c-02ff-432a-ac6d-c6ba35871896",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import (\n",
    "  create_retrieval_chain\n",
    ")\n",
    "from langchain import hub\n",
    "\n",
    "\n",
    "retrieval_qa_chat_prompt = hub.pull(\"langchain-ai/retrieval-qa-chat\")\n",
    "combine_docs_chain = create_stuff_documents_chain(llm, retrieval_qa_chat_prompt)\n",
    "retrieval_qa_chain = create_retrieval_chain(retriever, combine_docs_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10550e5-7495-4298-8f8a-bc9899e71930",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "answer = retrieval_qa_chain.invoke({'input': query})\n",
    "pp.pprint(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e29eae5-c463-4153-9167-e4628c74d13c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cleanup\n",
    "\n",
    "To avoid incurring future charges, delete the resources. You can do this by deleting the CloudFormation template used to create the IAM role and SageMaker notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ce3fe8-bb71-4e22-a551-2475eb2d16b7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "In this notebook we were able to see how to use LLMs provided on Amazon Bedrock to generate embeddings and then ingest those embeddings into Amazon OpenSearch Service Serverless and finally do a similarity search for user input to the documents (embeddings) stored in the OpenSearch Service Searverless. We used langchain as an abstraction layer to talk to both Amazon Bedrock as well as Amazon OpenSearch Service Serverless."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd881bab",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "  * [Amazon Bedrock Knowledge Base - Samples for building RAG workflows](https://github.com/aws-samples/amazon-bedrock-samples/tree/main/knowledge-bases) - This repository contains examples for customers to get started using the Amazon Bedrock Service.\n",
    "  * [Build a powerful question answering bot with Amazon SageMaker, Amazon OpenSearch Service, Streamlit, and LangChain](https://aws.amazon.com/blogs/machine-learning/build-a-powerful-question-answering-bot-with-amazon-sagemaker-amazon-opensearch-service-streamlit-and-langchain/)\n",
    "  * [Using the Amazon SageMaker Studio Image Build CLI to build container images from your Studio notebooks](https://aws.amazon.com/blogs/machine-learning/using-the-amazon-sagemaker-studio-image-build-cli-to-build-container-images-from-your-studio-notebooks/)\n",
    "  * [LangChain](https://python.langchain.com/docs/get_started/introduction.html) - A framework for developing applications powered by language models.\n",
    "  * [LangChain-AWS](https://python.langchain.com/v0.1/docs/integrations/platforms/aws/) - The `LangChain` integrations related to `Amazon AWS` platform.\n",
    "  * [LangChain > Components > Chains](https://python.langchain.com/v0.1/docs/modules/chains/) - Chains refer to sequences of calls - whether to an LLM, a tool, or a data preprocessing step. The primary supported way to do this is with [LCEL](https://python.langchain.com/v0.1/docs/expression_language/).\n",
    "  * [LangChain Use cases > Q&A with RAG](https://python.langchain.com/v0.1/docs/use_cases/question_answering/)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:123456789012:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
